{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b6695a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('..') # Pour pouvoir importer depuis src/\n",
    "from src.features import frac_diff_ffd, find_min_d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a245e051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Charger Data\n",
    "df = pd.read_csv('../data/raw/train.csv').set_index('date_id').sort_index()\n",
    "df = df.ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d188bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Liste des coupables (Tes colonnes Non-Stationnaires)\n",
    "# Tu peux aussi automatiser ça en reprenant le code du notebook 01\n",
    "cols_to_fix = ['P10', 'P11', 'I5', 'I8', 'I9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1246ff81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Réparation des Features Non-Stationnaires ---\n",
      "Traitement de P10...\n",
      "  -> Meilleur d = 0.1 (p-value: 0.0000)\n",
      "Traitement de P11...\n",
      "  -> Meilleur d = 0.1 (p-value: 0.0001)\n",
      "Traitement de I5...\n",
      "  -> Meilleur d = 0.1 (p-value: 0.0098)\n",
      "Traitement de I8...\n",
      "  -> Meilleur d = 0.1 (p-value: 0.0492)\n",
      "Traitement de I9...\n",
      "  -> Meilleur d = 0.1 (p-value: 0.0202)\n"
     ]
    }
   ],
   "source": [
    "# 3. La boucle de réparation\n",
    "new_features = pd.DataFrame(index=df.index)\n",
    "\n",
    "print(\"--- Réparation des Features Non-Stationnaires ---\")\n",
    "for col in cols_to_fix:\n",
    "    print(f\"Traitement de {col}...\")\n",
    "    \n",
    "    # A. Trouver le meilleur d\n",
    "    best_d, p_val = find_min_d(df[col])\n",
    "    \n",
    "    print(f\"  -> Meilleur d = {best_d} (p-value: {p_val:.4f})\")\n",
    "    \n",
    "    # B. Appliquer la transformation\n",
    "    # Attention: FFD coupe le début des données (mémoire). \n",
    "    # Ton index sera aligné, mais le début sera NaN.\n",
    "    new_series = frac_diff_ffd(df[col], d=best_d)\n",
    "    \n",
    "    # C. Sauvegarder\n",
    "    # On renomme pour garder une trace\n",
    "    new_features[f\"{col}_ffd\"] = new_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa5d5ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Fusionner avec le reste\n",
    "# On garde les features qui étaient déjà OK (Stationnaires)\n",
    "# On remplace les mauvaises par les versions FFD\n",
    "df_clean = df.drop(columns=cols_to_fix).join(new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ac8680d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Création des features dérivées (Volatilité & Corrélation)...\n",
      "Nouvelles dimensions avec features dérivées : (2052, 100)\n"
     ]
    }
   ],
   "source": [
    "# --- AJOUT DE FEATURES DE SECOND ORDRE (López de Prado Chap. 17) ---\n",
    "print(\"Création des features dérivées (Volatilité & Corrélation)...\")\n",
    "\n",
    "# 1. Volatilité Glissante (50 jours) sur les séries FFD\n",
    "# Cela capture le \"Régime de marché\" (Calme vs Panique)\n",
    "df_clean['P10_ffd_vol'] = df_clean['P10_ffd'].rolling(window=50).std()\n",
    "df_clean['I5_ffd_vol'] = df_clean['I5_ffd'].rolling(window=50).std()\n",
    "\n",
    "# 2. Corrélation Glissante (50 jours)\n",
    "# Capture la dynamique entre Prix et Taux (Risk On / Risk Off)\n",
    "df_clean['corr_P10_I5'] = df_clean['P10_ffd'].rolling(window=50).corr(df_clean['I5_ffd'])\n",
    "\n",
    "# 3. Nettoyage des NaNs créés par le Rolling (les 50 premiers jours)\n",
    "df_clean = df_clean.dropna()\n",
    "\n",
    "print(f\"Nouvelles dimensions avec features dérivées : {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8733ea0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier sauvegardé avec succès : ../data/processed/train_stationary.parquet\n"
     ]
    }
   ],
   "source": [
    "# 5. SAUVEGARDE (C'est l'étape qui manquait !)\n",
    "save_path = '../data/processed/train_stationary.parquet'\n",
    "df_clean.to_parquet(save_path)\n",
    "print(f\"Fichier sauvegardé avec succès : {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udes_sd_a25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
