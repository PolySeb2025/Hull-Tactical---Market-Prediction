# Hull Tactical - Market Prediction ğŸ“ˆğŸ¤–

Ce projet implÃ©mente un pipeline de Machine Learning avancÃ© pour la prÃ©diction de mouvements de marchÃ© (Market Prediction). Il s'appuie sur des techniques de finance quantitative pour traiter des sÃ©ries temporelles non stationnaires et prÃ©dire les rendements futurs.

## ğŸš€ FonctionnalitÃ©s ClÃ©s

* **DiffÃ©renciation Fractionnaire (FFD) :** Transformation des sÃ©ries temporelles pour les rendre stationnaires tout en prÃ©servant la mÃ©moire Ã  long terme, implÃ©mentÃ©e dans `src/features.py`.
* **Ensemble Modeling :** Utilisation combinÃ©e de **XGBoost** et **LightGBM** pour la classification.
* **InfÃ©rence Temps RÃ©el :** Une classe `Model` optimisÃ©e pour la production, capable de calculer les features FFD de maniÃ¨re incrÃ©mentale sur des flux de donnÃ©es "live".
* **Feature Engineering AvancÃ© :** SÃ©lection automatique des 20 meilleures features pour Ã©viter le surapprentissage.
* **Analyse de StationnaritÃ© :** Tests Augmented Dickey-Fuller (ADF) pour valider la robustesse des features.

## ğŸ“‚ Structure du Projet

```text
hull_mldp_project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                # DonnÃ©es brutes (train.csv, test.csv)
â”‚   â””â”€â”€ processed/          # DonnÃ©es transformÃ©es (parquet)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ exploration.ipynb   # Analyse exploratoire et tests ADF
â”‚   â”œâ”€â”€ features_ffd.ipynb  # CrÃ©ation des features fractionnaires
â”‚   â”œâ”€â”€ labeling.ipynb      # CrÃ©ation des cibles (Targets)
â”‚   â””â”€â”€ training2.ipynb     # Pipeline final : Split, SÃ©lection, Ensemble Learning
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ features.py         # Algorithmes FFD (Fixed Window)
â”‚   â”œâ”€â”€ labeling.py         # Logique de labeling
â”‚   â””â”€â”€ sampling.py         # Poids d'Ã©chantillonnage (Uniqueness)
â””â”€â”€ submission/
    â”œâ”€â”€ model.py            # Script d'infÃ©rence pour la production
    â”œâ”€â”€ features_list.pkl   # Liste des features retenues
    â””â”€â”€ model_lpd.pkl       # ModÃ¨le sÃ©rialisÃ©
```

## ğŸ› ï¸ Installation

Assurez-vous d'avoir Python 3.10+ et installez les dÃ©pendances nÃ©cessaires :


```bash
pip install pandas numpy scikit-learn xgboost lightgbm statsmodels pyarrow joblib matplotlib seaborn
```

## âš¡ Workflow

Pour reproduire le pipeline complet, exÃ©cutez les notebooks dans l'ordre suivant :

    Exploration (exploration.ipynb) : Chargement des donnÃ©es et analyse de la stationnaritÃ© des variables brutes.

    Feature Engineering : Calcul des features FFD pour capturer la mÃ©moire du marchÃ© sans sacrifier la stationnaritÃ©.

    EntraÃ®nement (training3.ipynb) :

        Calcul des poids d'Ã©chantillons.

        SÃ©lection de features.

        EntraÃ®nement de l'ensemble (XGBoost + LightGBM).

        GÃ©nÃ©ration du fichier de soumission.

## ğŸ§  DÃ©tails du ModÃ¨le

Le modÃ¨le final (submission/model.py) est conÃ§u pour Ãªtre dÃ©ployÃ©. Il intÃ¨gre une mÃ©moire historique (self.history) permettant de recalculer
les indicateurs techniques complexes (comme le FFD) Ã  chaque nouveau point de donnÃ©e reÃ§u, garantissant une cohÃ©rence parfaite entre l'entraÃ®nement et l'infÃ©rence.



